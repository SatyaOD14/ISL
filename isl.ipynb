{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb01de35",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install mediapipe opencv-python pandas\n",
    "\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import display, Javascript\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def take_photo(filename='photo.jpg', quality=0.8):\n",
    "  js = Javascript('''\n",
    "    async function takePhoto(quality) {\n",
    "      const div = document.createElement('div');\n",
    "      const capture = document.createElement('button');\n",
    "      capture.textContent = 'üì∏ Capture';\n",
    "      div.appendChild(capture);\n",
    "\n",
    "      const video = document.createElement('video');\n",
    "      video.style.display = 'block';\n",
    "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "\n",
    "      document.body.appendChild(div);\n",
    "      div.appendChild(video);\n",
    "      video.srcObject = stream;\n",
    "      await video.play();\n",
    "\n",
    "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
    "\n",
    "      await new Promise((resolve) => capture.onclick = resolve);\n",
    "\n",
    "      const canvas = document.createElement('canvas');\n",
    "      canvas.width = video.videoWidth;\n",
    "      canvas.height = video.videoHeight;\n",
    "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "      stream.getTracks().forEach(track => track.stop());\n",
    "      div.remove();\n",
    "\n",
    "      return canvas.toDataURL('image/jpeg', quality);\n",
    "    }\n",
    "  ''')\n",
    "  display(js)\n",
    "  data = eval_js('takePhoto({})'.format(quality))\n",
    "  binary = b64decode(data.split(',')[1])\n",
    "  with open(filename, 'wb') as f:\n",
    "    f.write(binary)\n",
    "  return filename\n",
    "\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def extract_keypoints(results):\n",
    "    if results.multi_hand_landmarks:\n",
    "        hand = results.multi_hand_landmarks[0]\n",
    "        keypoints = []\n",
    "        for lm in hand.landmark:\n",
    "            keypoints.append(lm.x)\n",
    "            keypoints.append(lm.y)\n",
    "        return keypoints\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def create_dataset_folder(label):\n",
    "    folder = f\"/content/dataset/{label}\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    return folder\n",
    "\n",
    "\n",
    "# üîÅ Repeat this block for each image you want to capture\n",
    "label = \"namaste\"  # Change this label each time you record a new sign\n",
    "filename = take_photo()\n",
    "image = cv2.imread(filename)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "results = hands.process(image_rgb)\n",
    "\n",
    "if results.multi_hand_landmarks:\n",
    "    mp_drawing.draw_landmarks(image, results.multi_hand_landmarks[0], mp_hands.HAND_CONNECTIONS)\n",
    "    keypoints = extract_keypoints(results)\n",
    "    if keypoints:\n",
    "        folder = create_dataset_folder(label)\n",
    "        filepath = os.path.join(folder, f\"{label}_{np.random.randint(1000)}.csv\")\n",
    "        pd.DataFrame([keypoints]).to_csv(filepath, index=False)\n",
    "        print(f\"‚úÖ Keypoints saved to {filepath}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Hand detected but keypoints missing.\")\n",
    "else:\n",
    "    print(\"üö´ No hand detected.\")\n",
    "\n",
    "# Show the captured and annotated image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import glob\n",
    "\n",
    "def load_dataset(data_dir=\"/content/dataset\"):\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "\n",
    "    for label_folder in os.listdir(data_dir):\n",
    "        folder_path = os.path.join(data_dir, label_folder)\n",
    "        for file in glob.glob(f\"{folder_path}/*.csv\"):\n",
    "            df = pd.read_csv(file)\n",
    "            if df.shape[1] == 42:  # Make sure it‚Äôs a full hand keypoints file\n",
    "                all_data.append(df.values[0])\n",
    "                all_labels.append(label_folder)\n",
    "\n",
    "    return np.array(all_data), np.array(all_labels)\n",
    "\n",
    "X, y = load_dataset()\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Labels:\", np.unique(y))\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from IPython.display import display, Javascript\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "from PIL import Image\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "# MediaPipe hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5)\n",
    "\n",
    "def take_photo_for_prediction(filename='test.jpg', quality=0.8):\n",
    "    js = Javascript('''\n",
    "        async function takePhoto(quality) {\n",
    "            const div = document.createElement('div');\n",
    "            const capture = document.createElement('button');\n",
    "            capture.textContent = 'üì∏ Capture';\n",
    "            div.appendChild(capture);\n",
    "\n",
    "            const video = document.createElement('video');\n",
    "            video.style.display = 'block';\n",
    "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "\n",
    "            document.body.appendChild(div);\n",
    "            div.appendChild(video);\n",
    "            video.srcObject = stream;\n",
    "            await video.play();\n",
    "\n",
    "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
    "\n",
    "            await new Promise((resolve) => capture.onclick = resolve);\n",
    "\n",
    "            const canvas = document.createElement('canvas');\n",
    "            canvas.width = video.videoWidth;\n",
    "            canvas.height = video.videoHeight;\n",
    "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "            stream.getTracks().forEach(track => track.stop());\n",
    "            div.remove();\n",
    "\n",
    "            return canvas.toDataURL('image/jpeg', quality);\n",
    "        }\n",
    "    ''')\n",
    "    display(js)\n",
    "    data = eval_js('takePhoto({})'.format(quality))\n",
    "    binary = b64decode(data.split(',')[1])\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(binary)\n",
    "    return filename\n",
    "\n",
    "\n",
    "filename = take_photo_for_prediction()\n",
    "image = cv2.imread(filename)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "results = hands.process(image_rgb)\n",
    "\n",
    "if results.multi_hand_landmarks:\n",
    "    hand_landmarks = results.multi_hand_landmarks[0]\n",
    "    keypoints = []\n",
    "    for lm in hand_landmarks.landmark:\n",
    "        keypoints.extend([lm.x, lm.y])\n",
    "\n",
    "    # Ensure it's 42 features\n",
    "    if len(keypoints) == 42:\n",
    "        prediction = clf.predict([keypoints])[0]\n",
    "        print(\"‚úÖ Predicted Sign:\", prediction)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Incomplete hand detected.\")\n",
    "else:\n",
    "    print(\"‚ùå No hand detected.\")\n",
    "\n",
    "# Move into your repo directory (if not already there)\n",
    "%cd your-repo\n",
    "\n",
    "# Stage changes (this adds your file to Git tracking)\n",
    "!git add .\n",
    "\n",
    "# Commit changes with a message\n",
    "!git commit -m \"Added notebook from Colab\"\n",
    "\n",
    "# Push to GitHub (you'll be prompted for GitHub username and token)\n",
    "!git push origin main\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
